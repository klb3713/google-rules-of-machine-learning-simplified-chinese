# 特征工程

 在机器学习系统生命周期的第一个阶段，重要的是给系统喂训练数据，关注感兴趣的指标，并且部署上线。**一旦你把这套系统从头到尾建立好了，并且加上必要的单元和系统性测试后，就可以进入第二阶段了。**

 在第二阶段，有很多成果唾手可得。会有很多显然的特征可以加进系统。因此，通常第二阶段会需要尽可能往系统里面塞特征，并且进行简单的组合。在这个阶段，所有指标可能都持续增长。会有很多的发布，这个时候也是拉人往你的nb系统里扔数据的绝佳时机。

## Rule 16 - 计划发布和迭代

 别指望你现在的模型是最终发布的版本，更别指望有一天你会停止发布模型。所以注意你现在给系统增加的复杂度，是否会拖慢未来的发布。很多团队按照季度，甚至按照年度来发布模型。关于发布模型，这里有三个基本原因：

 1. 你增加了新特征,
 2. 你调整了正则方式，用新方式组合老特征，并且/或者
 3. 你调整了优化目标.

无论怎样，在模型上上点心总是好的：关注喂给模型的新老数据，会帮助你捕捉系统的新信号。所以，当你构建模型时候，想想增加、移除、组合各种特征容易吗。想想复制 pipeline 并且让其在其他地方运转良好容易吗。想想是否可以两三条并行计算。最后，不用担心16号特征或者35号特征是否还有用，反正下个 Q 你就得考虑这个问题了。

> Eric：最后一句同样没太看懂。

## Rule 17 - 从直接观察到和得到的特征 而非习得的特征开始

这也许是个争议点，但是它的确可以避免很多坑。首先，我们看一下什么是习得特征。习得特征是被外部系统（比如无监督聚类系统）或者学习器自己（比如向量机或者深度学习）学习产生的特征。这些特征也许有用，但是同样也会带来不少问题，尽量别在你的第一个模型上用这些特征。如果你用外部系统产生一个特征，一定记得这个外部系统是要有他自己的优化目标。外部系统的目标也许和你的模型只有很弱的相关性。你用了外部系统的一个快照，他就会过时。如果你更新了外部系统的特征，意义也许就变了。如果你的确用了外部系统产生的特征，一定要多加小心。
向量机和深度模型最大的问题是--他们是非凸的。也就是说，没法保证能够得到甚至逼近全局最优解，每次迭代，可能都会得到不同的局部最优解。这种不确定性使得很难判断究竟系统的变化是某个特这个你变更带来的，还是纯粹随机得来。不用一些深度特征，你也能得到非常不错的基线表现。等你达成了基线，再试那些深奥的方式不迟。

## Rule 18 - 探索那些不同上下文产生内容的特征

 通常，一个机器学习系统是一个大得多的系统的一小部分。例如，你可以想象一篇可以用在 What's Hot（今日热点）中的帖子，在它出现在今日热点之前，也许很多人已经+1，分享或者评论了。如果你把这些特征给到学习器，他就能把 What' Hot 之外的更多帖子找到。Youtube 的 Watch Next，可以用Youtube搜索当中的观看数量，或者共同观看数量（就是某视频在其他视频之后被观看的次数）作为特征。你也可以使用明确的用户打分。最后，如果你用某一个用户行为作为 label，找到其他上下文的同样的行为作为特征就很不错。这些特征，都能帮你把新内容引入上下文。注意这可不是个性化：先找到当前上下文谁更喜欢这些内容，然后在找到谁更或者更不喜欢它。

 > Eric: 最后一句没看懂。

## Rule 19 - 尽量使用明确的特征

有了大量数据，可以很容易得到数以百万记的简单特征，而非几个复杂特征。召回的文档ID或者映射的Query泛化性也许并不好，但是足够帮你在热门query上排序。因此，不必担心那些只在小部分数据上适用的特征，他们的总体覆盖率也许超过90%。你还可以用正则化来消减那些样本覆盖太小的特征。

## Rule 20 - 用人类能理解的方式去组合和修改那些现有特征以创造新特征

有很多方式来组合修改特征。机器学习系统，比如 TensorFlow 可以有[很多方式](https://www.tensorflow.org/tutorials/linear/overview#feature-columns-and-transformations))帮你预处理数据。两个最标准的方法是"离散化"和"交叉"。
 离散化是指拿到一个连续特征，然后基于他产生很多离散特征。就拿"年龄"这个连续特征来说，你可以创造一个特征，当年龄小于18岁时候，这个特征取1。再创造一个特征，当年龄在18到35之间时候取1，等等。不用太担心这样做会没有终点，只要覆盖大多数范围效果就很明显了。交叉组合两个或者多个特征，在 TensorFlow里是指把不同的特征列组合起来。一个特征列是指同质的信息集合，比如{男，女}, {美国，加拿大，墨西哥}等等。组合是指这些交叉组合起来，比如笛卡儿积:**{男，女} * {美国，加拿大，墨西哥}。新得特征列可能就变成类似（男，加拿大）这种。如果你用 TensorFlow 来帮你做特征交叉，这种特征就会出现在男性加拿大人的样本中。注意，要想让特征交叉起作用，需要大量的数据进行训练。

交叉产生大量新特征的时候会产生过拟合问题。比如，你在做搜索，一个特征是query中的搜索词，一个特征是 document 中的词。当你做交叉的时候，也许产生大量的新特征（见 Rule #21）。当处理文本的时候，通常有两个选择。最残酷的是点乘，简版的点乘是指计算 query 和 document 同时出现词的数量。另一个选择是交叉，每个词是否同时出现在 query 和 document 里都有独立的特征去体现。

> Eric: 这段翻译得不是很顺。需要丰富一下。

## Rule 21 - 线性模型中你能学到的特征数量与你能得到的数据量正相关

虽然已经有 nb 的学习理论去证明了模型复杂度，但是你记住这条原则基本就够了。我和别人聊这类问题的时候，经常听他们说怀疑几千个样本根本学不到啥，或者你需要一百万个样本才能学一个像样的模型出来，他们这么说的时候通常被卡在某个模型的学习上没进展。关键是你的学习方法要和数据规模相匹配：

1. 如果你面对的是一个搜索排序系统，文档和搜索词中有上百万的不同 words，那么你就应该用query 与文档的点乘来扩充 feature，比如用[TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf), 也要搭配一大批人工特征。一千样本，对应十来个特征。

2. 如果你 有上百万的样本，那就交叉文档和query，正则化特征并做必要的选择。也许你会得到上百万的特征，然后正则化会让其变少一点。上千万的样本，也许上10w 的特征。

3. 如果你有10亿，或者数百亿的样本，你可以直接交叉 document 和 query 的 token，用上特征选择和正则化。10亿样本对应千万级的特征。

 统计的学习理论很少给你很死的限制，但是拿来做指导还是很不错的。最后，用**Rule #28**讲到的原则去选择用哪些特征。

## Rule 22 - 清理那些你不再用到的特征

 无用特征欠下技术债。如果你发现某个特征和与他有关的特征组合都没啥用了，就果断把它从你的系统里清理掉。系统干干净净，你才能快速发现那些有前途的特征。如有必要，其他人会再把特征加回来的。时刻记得特征覆盖率，以此评判哪些特征需要保留。特征覆盖了多少样本？例如，如果你的某个个性化特征只有8%的覆盖率，也许留着他就没那么高效了。同时，也许有些特征punch above their weight. 比如，如果你有一个特征只覆盖了1%的数据，但是90%的正样本都有这个特征，那么就应该加。

> Eric: 什么叫 punch above their weight?
